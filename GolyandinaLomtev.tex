\documentclass[10pt]{article}

\usepackage[text={14cm,20cm}]{geometry}

\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{latexsym,amssymb,amsthm}
\usepackage{euscript}

%do not number figure as it is only one of them
\usepackage{caption}

\newtheorem{definition}{Определение}
\newtheorem{theorem}{Теорема}
\newtheorem{proposition}{Утверждение}
\newtheorem{lemma}{Лемма}
\newtheorem{remark}{Замечание}
\newtheorem{consequence}{Следствие}
\def\matrA{\mathop{\mathrm{A}}}
\def\matr{\mathbf}
\def\func{\mathop\mathrm}
\def\ED{\mathbb}
%\def\trans{\mathop{\mathrm{T}}}
\def\trans{{\mathrm{T}}}
\newcommand{\T}[1]{#1^{\mathop{\mathrm{T}}}}
\newcommand{\normP}[1]{\left\| #1 \right\|_{P}}
\newcommand{\toptau}[1]{ \overline{#1}^{(\tau)} }
\newcommand{\bottau}[1]{ \underline{#1}_{(\tau)} }
\newcommand{\lefttau}[1]{ _{(\tau)}~\!\!\vert~\!\!#1 }
\newcommand{\righttau}[1]{ #1~\!\!\vert_{(\tau)} }

\newcommand{\toptauT}[2]{ \overline{#1}^{(#2)} }
\newcommand{\bottauT}[2]{ \underline{#1}_{(#2)} }
\newcommand{\lefttauT}[2]{ _{(#2)}\!\vert  #1 }
\newcommand{\righttauT}[2]{ #1\vert_{(#2)} }
\newcommand{\Q}{Q}
\def\spaceR{\mathsf{R}}
\def\wtilde{\widetilde}
\def\what{\widehat}

\newcommand{\norm}[1]{\left\| #1 \right\|}
\newcommand{\modul}[1]{\left| #1 \right|}
\newcommand{\argmax}{\mbox{argmax}}
\def\vect{\mathbf}
\newcommand{\bracket}[1]{\left(#1\right)}
\newcommand{\brackettt}[1]{(#1)}
\newcommand{\bfgh}{\begin{figure}[!ht]}
\newcommand{\efg}{\end{figure}}

\makeatletter
\def\@biblabel#1{#1. }
\makeatother

\newcommand{\tX}{\mathbb{X}}
\newcommand{\tY}{\mathbb{Y}}
\newcommand{\cM}{\EuScript{M}}
\newcommand{\calT}{\mathcal{T}}
\newcommand{\calH}{\mathcal{H}}
\newcommand{\gX}{\mathfrak{X}}

\usepackage[compact]{titlesec}
\titlespacing{\section}{0pt}{*1}{*0}
\titlespacing{\subsection}{0pt}{*1}{*0}
\titlespacing{\subsubsection}{0pt}{*1}{*0}


%\input{letters_series_mathbb}
% Использовать полужирное начертание для векторов
\let\vec=\mathbf
%\renewcommand{\cdsep}{\\}
\newcommand{\secondskip}{3.5cm}
\newcommand{\sixthskip}{2.5cm}
\renewcommand{\hat}[1]{\widehat{#1}}

% Включать подсекции в оглавление
\setcounter{tocdepth}{2}

%\graphicspath{{fig/}}
%----------------------------------------------------------------
\begin{document}
    \begin{center}
      {\Large Улучшение разделимости временных рядов в анализе сингулярного спектра с помощью одного метода анализа независимых компонент}\\[0.5cm]
      {Голяндина Н.Э.\footnote{Работа частично поддержана грантом РФФИ номер 15-04-06480}, Ломтев М.А.}\\[0.4cm]
      УДК 519.246.8+519.254
    \end{center}

%\begin{abstract}
%Рассматривается модификация SSA-AMUSE метода анализа сингулярного спектра для улучшения разделимости компонент временного ряда.
%Предлагаемая модификация ослабляет условия так называемой сильной разделимости, приводя к улучшению точности разделения компонент
%по сравнению с аналогичным методом. В работе приведено обоснование алгоритма, а также получены условия разделимости
%для нового метода. Применение условий разделимости продемонстрировано для случая разделимости двух гармоник.
%На численном примере показано преимущество разработанного метода по сравнению с существующим.
%\end{abstract}

\section*{Введение}
В анализе временных рядов есть важная задача представления наблюдаемого ряда в виде
суммы интерпретируемых компонент, таких как тренд, периодики, шум.
%
Одним из методов, решающих эту задачу без задания параметрической модели компонент,
является метод анализа сингулярного спектра (Singular Spectrum Analysis, коротко, SSA),
см. монографии \cite{Golyandina.etal2001, Golyandina.Zhigljavsky2012} и ссылки внутри.
%
Идея метода состоит в построении так называемой траекторной матрицы временного ряда,
ее сингулярного разложения с последующей группировкой матричных компонент сингулярного разложения
и перехода обратно от сгруппированного матричного разложения к разложению временного ряда.

Понятие разделимости компонент временного ряда связано со способностью метода с помощью
правильной группировки выделить эти компоненты из наблюдаемой суммы.
%
Слабая разделимость рядов $\tX^{(1)}$ и $\tX^{(2)}$ означает, что существует такое сингулярное разложение траекторной
матрицы ряда $\tX =\tX^{(1)} + \tX^{(2)}$, которое можно сгруппировать в две группы, одна из которых соответствует
$\tX^{(1)}$, а вторая --- $\tX^{(2)}$. Сильная разделимость означает, что для любого сингулярного
разложения это так.

В ряде случаев, например, в случае слабой разделимости двух синусов с разными частотами и одинаковыми амплитудами,
сильная разделимость отсутствует \cite{Golyandina.etal2003}.

Возникает задача построения другого оптимизационного критерия, который
мог бы сильно разделить компоненты, не разделённые с помощью SSA, использующего оптимальные свойства сингулярного разложения.
Метод решения этой задачи, называемый DerivSSA, был предложен в работе \cite{DerivSSA}. Метод DerivSSA меняет вклады компонент, рассматривая не только сам ряд, но и его производную.

Метод, предлагаемый в этой работе, использует идею метода анализа независимых компонент (Independent Component Analysis, коротко, ICA \cite{HyvarinenE2000}). В \cite{Golyandina.Zhigljavsky2012} упоминается использование FastICA для разделения компонент в рамках SSA, но там применяется метод ICA, который исходно был разработан для анализа многомерных данных \cite{Hyvarinen99, HyvarinenE2000}. Здесь мы будем использовать метод AMUSE, предложенный для разделения случайных сигналов \cite{Tong1991,Cardoso,HyvarinenE2000} и более подходящий для анализа временных рядов.

Опишем структуру работы. В разделе \ref{SSA} кратко рассматривается метод Basic SSA и понятия разделимости, связанные с ним. В разделе \ref{SSA_ICA} описан предлагаемый метод SSA-AMUSE и проведено его обоснование.  В разделе \ref{SSA_ICA_separ} доказываются утверждения относительно условий разделимости
с помощью предлагаемого метода и приводятся примеры. В частности, результаты показывают, что метод SSA-AMUSE, в отличие от Basic SSA, разделяет гармонические компоненты независимо от значений амплитуды. В разделе \ref{Comparison} представлено численное сравнение SSA-AMUSE с DerivSSA на примере
и показано его преимущество.

\section{Метод Basic SSA}
\label{SSA}
%В \cite{Golyandina2001} приводится базовый алгоритм SSA, состоящий из следующих шагов: вложение, сингулярное разложение траекторной матрицы, группировка, диагональное усреднение.
Рассмотрим вещественнозначный ненулевой временной ряд $\tX_N\!=\!(x_1,\ldots,x_{N})$. Пусть $L$ ($1<L<N$) --- целое число, называемое {\em длиной окна}, и $K=N-L+1$.

Обозначим  $\cM_{L,K}$ линейное пространство матриц размера $L\times K$,
$\cM_{L,K}^{(H)}$ линейное пространство ганкелевых матриц размера $L\times K$,
$X_i=(x_{i},\ldots,x_{i+L-1})^\trans$, $i=1,\ldots,K$, и $\matr{X}=[X_1:\ldots:X_K]$ {\em $L$-траекторную матрицу} ряда $\tX_N$.
%
Введём оператор вложения $\calT: \spaceR^{N} \mapsto \cM_{L,K}$ как $\calT(\tX_N)=\matr{X}$ и ортогональный проектор $\calH$ (по норме Фробениуса) из $\cM_{L,K}$ в $\cM_{L,K}^{(H)}$.

Согласно \cite[глава 1]{Golyandina.etal2001} коротко опишем алгоритм Basic SSA. Метод состоит из четырёх шагов:

\smallskip
{\bf Вложение.}
Выберем длину окна $L$, $1<L<N$. На шаге Вложение исходный ряд переводится в траекторную матрицу: $\matr{X}=\calT(\tX_N)$.

\smallskip
{\bf Сингулярное разложение.}
В результате шага получаем сингулярное разложение траекторной матрицы $\matr{X}$:
	$\matr{X} = \sqrt{\lambda_1}U_1V_{1}^{\trans} +\ldots+\sqrt{\lambda_d}U_dV_{d}^{\trans}=\matr{X}_1 + \ldots + \matr{X}_d$.
 Здесь $d=\func{rank} \matr{X}$, элементарные матрицы $\matr{X}_i$ имеют ранг 1 и упорядочены по убыванию сингулярных чисел $\sqrt{\lambda_i}$. Набор $(\sqrt{\lambda_i},U_i,V_i)$ называется \textsl{$i$-ой собственной тройкой}.

\smallskip
{\bf Группировка.}
На основе полученного на втором шаге разложения делим множество индексов $\left\{1,\ldots,d\right\}$ на $m$ непересекающихся подмножеств $I_1,\ldots,I_m$.

\textsl{Результирующей матрицей} $\matr{X}_I$, соответствующей некоторой группе индексов $I$, называется матрица $\matr{X}_I \!=\! \sum\limits_{i\in I}\matr{X}_i$.
Вычисляя результирующие матрицы по каждому подмножеству $I_1,\ldots,I_m$, получаем $\matr{X}=\matr{X}_{I_1} + \ldots + \matr{X}_{I_{m}}$.
Процедура выбора подмножеств $I_1,\ldots,I_m$ называется \textsl{группировкой собственных троек}.

\smallskip
{\bf Диагональное усреднение.}
Получим ряды, применив к результирующим матрицам диагональное усреднение:
$
\wtilde{\matr{X}}^{(k)} = \calH \matr{X}_{I_k},\ \  \wtilde\tX^{(k)}_N = \calT^{-1} \wtilde{\matr{X}}^{(k)}.
$

Таким образом, исходный ряд раскладывается в сумму рядов:
$
\tX_N = \sum\limits_{k=1}^m\wtilde\tX^{(k)}_N.
$
К примеру, при правильной группировке, таким образом можно получить разложение ряда на тренд, сумму гармоник и шум.

\subsection{Разделимость}
Дадим общие определения сильной и слабой разделимости.
Пусть наблюдаемый ряд имеет вид $\tX_N = \tX_{N}^{(1)} + \tX_{N}^{(2)}$.
 Пусть $\matr{X}$, $\matr{X}^{(1)}$ и $\matr{X}^{(2)}$ --- соответствующие $L$-траекторные матрицы. Обозначим $\gX^{(L,1)}$ и $\gX^{(L,2)}$ линейные пространства, порождённые столбцами матриц $\matr{X}^{(1)}$ и $\matr{X}^{(2)}$, а $\gX^{(K,1)}$ и $\gX^{(K,2)}$ --- линейные пространства, порождённые их строками. Пусть есть метод A, который представляет траекторную матрицу $\matr{X}$ в виде суммы элементарных матриц, причём, возможно, не единственным способом.

\begin{definition}
\label{def:sep_w}
	Ряды $\tX^{(1)}_N$ и $\tX^{(2)}_N$ назовём слабо $L$-разделимыми методом A, если существует такое разложение траекторной матрицы $\matr{X}$ на элементарные, полученное методом A, которое можно разбить на две группы элементарных матриц так, что каждая даёт в сумме $\matr{X}^{(1)}$ и $\matr{X}^{(2)}$ соответственно.
\end{definition}

\begin{definition}
\label{def:sep_s}
	Ряды $\tX^{(1)}_N$ и $\tX^{(2)}_N$ назовём сильно $L$-разделимыми методом A, если любое разложение траекторной матрицы $\matr{X}$ на элементарные, полученное методом A, можно разбить на две группы элементарных матриц так, что каждая даёт в сумме $\matr{X}^{(1)}$ и $\matr{X}^{(2)}$ соответственно.
\end{definition}

В \cite[разделы 1.5 и 6.1]{Golyandina.etal2001} содержатся следующие факты о разделимости.

\begin{proposition}
\label{prop:sep_w}
Ряды $\tX_{N}^{(1)}$ и $\tX_{N}^{(2)}$ слабо {$L$-разделимы} с помощью Basic SSA тогда и только тогда, когда линейные пространства $\gX^{(L,1)}$ и  $\gX^{(L,2)}$, $\gX^{(K,1)}$ и $\gX^{(K,2)}$ ортогональны.
\end{proposition}
\begin{proposition}
\label{prop:sep_s}
 Ряды $\tX_{N}^{(1)}$ и $\tX_{N}^{(2)}$  сильно {$L$-разделимы} с помощью Basic SSA тогда и только тогда, когда
  ряды $\tX_{N}^{(1)}$ и $\tX_{N}^{(2)}$ слабо $L$-разде\-ли\-мы и множества сингулярных чисел траекторных матриц $\matr{X}^{(1)}$ и $\matr{X}^{(2)}$ не пересекаются.
\end{proposition}

Заметим, что определения \ref{def:sep_w} и \ref{def:sep_s} не противоречат определениям, данным в \cite[разделы 1.5 и 6.1]{Golyandina.etal2001}
для разделимости методом Basic SSA, так как утверждения \ref{prop:sep_w} и \ref{prop:sep_s} дают возможность для двух эквивалентных определений слабой и сильной разделимости.

Класс разделимых рядов методом Basic SSA описан в \cite{Usevich2010}.

\subsection{Ряды конечного ранга. ЛРФ}
Дадим определение ряда конечного ранга и ряда, управляемого линейной рекуррентной формулой (ЛРФ) \cite[глава 5]{Golyandina.etal2001}.

\begin{definition}
	Ряд $\tX_N$ называется рядом конечного ранга $d < N/2$, если его $L$-траекторная матрица имеет ранг $d$ при любом $L \geq d$ таком, что $d \leq \min \bracket{L,K}$.
\end{definition}
\begin{definition}
	Ряд $\tX_N$ называется рядом, управляемым линейной рекуррентной формулой (ЛРФ) порядка $t$, $1 \leq t \leq N-1$, если существуют $a_1,\ldots,a_t$, $a_t \neq 0$, такие что
	\begin{gather}
	\label{LRR}
		x_{i+t}=\sum\limits_{k=1}^{t}a_k x_{i+t-k}, 1 \leq i \leq N-t.
	\end{gather}
	Если порядок $t$ минимально возможный, то ЛРФ (\ref{LRR}) называется минимальной. Минимальная ЛРФ единственна.
\end{definition}

Если ряд управляется минимальной ЛРФ порядка $d<N/2$, то он является рядом конечного ранга $d$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Алгоритм SSA-AMUSE}
\label{SSA_ICA}
Пусть наблюдаем ряд $\tX=\tX_N=(x_1,\ldots,x_{N})$ длины $N$, и $\tX_N=\tX_N^{(1)}+\tX_N^{(2)}$.

Приведём алгоритм, решающий проблему отсутствия сильной разделимости слабо разделимых рядов.
При этом слабо разделимые ряды остаются по-прежнему слабо разделимыми при немного изменённых условиях на
длину ряда и длину окна.

В Basic SSA базис строится на основе собственных векторов матрицы $\matr{X}\T{\matr{X}}$. Здесь идея состоит в замене сингулярного разложения разложением, используемым в методе AMUSE, применяемом для разделения независимых компонент сигнала. Поэтому будем называть предлагаемый нами метод SSA-AMUSE.

Метод AMUSE \cite{HyvarinenE2000} не обладает аппроксимационными свойствами, в частности, не предназначен для отделения сигнала от шума.
Поэтому метод SSA-AMUSE применяется как вложенный метод, уточняющий разложение, полученное с помощью Basic SSA:
в начале с помощью Basic SSA получаем оценку траекторной матрицы интересующего нас сигнала, потом полученную матрицу раскладываем с помощью SSA-AMUSE.

Таким образом, на первом этапе мы делаем обычное сингулярное разложение $L$-траекторной матрицы $\matr{X}$.
 Выделяем группу неразделившихся компонент с индексами $I$, $|I|=r$. Обозначим $\matr{Y}=\matr{X}_I$ сгруппированную матрицу этих компонент размерности $L \times K$ ранга $r$.
  Метод SSA-AMUSE строит разложение матрицы $\matr{Y}=\matr{Y}^{(1)}+\ldots+\matr{Y}^{(r)}$.
 После группировки согласно разбиению $I=\bigsqcup\limits_{k=1}^l J_k$ и последующего диагонального усреднения так же, как в Basic SSA, получаем разложение
$
\wtilde\tY_N = \wtilde\tY^{(1)}_N+\ldots+\wtilde\tY^{(l)}_N$, где $\wtilde\tY^{(k)}_N = \calT^{-1} \calH \matr{Y}_{J_k}.
$

В алгоритме SSA-AMUSE кроме параметра длины окна $L$ присутствует сдвиговый параметр $\tau \geq 1$. Мы будем описывать алгоритм с произвольным $\tau$. Однако, для получения сильной разделимости достаточно значения $\tau=1$.

В разделе \ref{sec:support}  приведём вспомогательные утверждения, необходимые для обоснования алгоритма, сформулированного в разделе \ref{sec:alg}.
Введём обозначение, которое является ключевым для алгоритма и связывает его с методом AMUSE анализа независимых компонент.

Пусть $\matr{B}$ --- произвольная матрица из $\cM_{A,B}$ и $\tau$ --- некоторое положительное целое число, $\tau < \min\bracket{A,B}$. Обозначим $\toptau{\matr{B}}$ матрицу $\matr{B}$ без первых $\tau$ строк, $\bottau{\matr{B}}$ матрицу $\matr{B}$ без последних $\tau$ строк, $\lefttau{\matr{B}}$ матрицу $\matr{B}$ без первых $\tau$ столбцов, $\righttau{\matr{B}}$ матрицу $\matr{B}$ без последних $\tau$ столбцов.

Положим
	\begin{gather}
	\label{C_tau}
\matr{C}_{\tau}\brackettt{\matr{B}} = 0.5 \left[\T{\bracket{\toptau{\matr{B}}}}\bottau{\matr{B}}+\T{\bracket{\bottau{\matr{B}}}}\toptau{\matr{B}}\right] \in \cM_{B,B}.
	\end{gather}

\subsection{Вспомогательные утверждения}
\label{sec:support}
				
\begin{lemma}
\label{svd_YY_}
	Пусть $\matr{Y} \in \cM_{L,K}$, $\func{rank}\matr{Y}=r$, $\tau \leq K/2$. Рассмотрим некоторое сингулярное разложение матрицы $\left[\lefttau{\matr{Y}}:\righttau{\matr{Y}}\right]=\matr{U}\matr{\Lambda}^{1/2}\T{\matr{T}}$,
где $\matr{\Lambda}\in \cM_{r,r}$ --- диагональная матрица с сингулярными числами на диагонали,
$\matr{U}\in \cM_{L,r}$ --- матрица левых сингулярных векторов, и $\matr{T}\in \cM_{2K-2\tau,r}$ --- матрица правых сингулярных векторов, тогда $\matr{T}=\left[\toptau{\matr{Q}}:\bottau{\matr{Q}}\right]$, где $\matr{Q}=\T{\matr{Y}}\matr{U}{\matr{\Lambda}}^{-1/2}$.
\end{lemma}

\begin{proof}
	Матрица $\left[\!\lefttau{\matr{Y}}\!:\!\righttau{\matr{Y}}\!\right]$ имеет ранг $r$, так как по условию включает все столбцы матрицы $\matr{Y}$. Сингулярное разложение матрицы $\left[\!\lefttau{\matr{Y}}\!:\!\righttau{\matr{Y}}\!\right]$ можно записать в виде
	%\begin{gather*}
		$\left[\lefttau{\matr{Y}}:\righttau{\matr{Y}}\right]=\left[\matr{U}\matr{\Lambda}^{1/2}\T{\bracket{\matr{T}^{(1)}}}:\matr{U}\matr{\Lambda}^{1/2}\T{\bracket{\matr{T}^{(2)}}}\right],$
	%\end{gather*}
	где $\matr{T}^{(1)}=\T{\bracket{\lefttau{\matr{Y}}}}\matr{U}\matr{\Lambda}^{-1/2}$ и $\matr{T}^{(2)}=\T{\bracket{\righttau{\matr{Y}}}}\matr{U}\matr{\Lambda}^{-1/2}$.
	Теперь возьмём $\matr{Q}=\T{\matr{Y}}\matr{U}\matr{\Lambda}^{-1/2}$. Равенства $\toptau{\matr{Q}}=\matr{T}^{(1)}$ и $\bottau{\matr{Q}}=\matr{T}^{(2)}$ следуют из правил перемножения матриц.
\end{proof}

\begin{remark}
\label{uut}
	Так как несложно показать, что столбцы матрицы $\matr{U}$ образуют ортонормированный базис пространства столбцов матрицы $\matr{Y}$, получаем $\matr{Y}=\matr{U}\T{\matr{U}}\matr{Y}$.
\end{remark}

\begin{consequence}
	$\matr{Y}=\matr{U}\matr{\Lambda}^{1/2}\T{\matr{\Q}}$.
\label{Y_ULQ}
\end{consequence}
\begin{proof}
	Следует из $\matr{Q}=\T{\matr{Y}}\matr{U}\matr{\Lambda}^{-1/2}$ и замечания \ref{uut}.
\end{proof}

%\begin{remark}
	Заметим, что столбцы матрицы $\matr{\Q}$ не являются ортогональными и нормированными.
%\end{remark}

\begin{lemma}
	Пусть матрица $\matr{Q} \in \cM_{K,r}$, и $\matr{C}_{\tau}\brackettt{\matr{Q}}=\matr{W}\matr{D}\T{\matr{W}}$ --- некоторое спектральное разложение $\matr{C}_{\tau}\brackettt{\matr{Q}}$. Тогда $\matr{D}=\matr{C}_{\tau}\brackettt{\matr{S}}$, где $\matr{S}=\matr{Q}\matr{W}$, и, следовательно, $\matr{C}_{\tau}\brackettt{\matr{S}}$ --- диагональная матрица.
\label{C_S_diag}
\end{lemma}
\begin{proof}
	Выводится подстановкой $\matr{S}=\matr{Q}\matr{W}$ в $\matr{C}_{\tau}\brackettt{\matr{S}}$ и перемножением матриц.
\end{proof}

Следующая теорема обосновывает разложение, которое является результатом работы метода SSA-AMUSE.

\begin{theorem}
\label{SSA_AMUSE_decomp}
Пусть $\matr{Y}$, $\matr{Q}$, $\matr{\Lambda}$, $\matr{U}$ и $r$ определены в лемме \ref{svd_YY_} и сдвиг $\tau\! \leq\! K/2$, а $\matr{W}$ и $\matr{S}=[S_1:\ldots:S_r]$ определены в лемме \ref{C_S_diag}. Тогда имеет место разложение $\matr{Y}=\sum\limits_{i=1}^{r}\hat{U}_i \T{S}_i$, где $\hat{U}_i$ --- столбцы матрицы $\hat{\matr{U}}=\matr{U}\matr{\Lambda}^{1/2}\matr{W}$.
%, $\matr{W}$ из спектрального разложения $\matr{C}_{\tau}\brackettt{\matr{Q}}=\matr{W}\matr{D}\T{\matr{W}}$, $\matr{Q}=\T{\matr{Y}}\matr{U}\matr{\Lambda}^{-1/2}$, $\matr{U}$ --- левые сингулярные векторы $\left[\lefttau{\matr{Y}}:\righttau{\matr{Y}}\right]$
\end{theorem}
\begin{proof}
	По следствию \ref{Y_ULQ} и лемме \ref{C_S_diag} $\matr{Y}=\matr{U}\matr{\Lambda}^{1/2}\matr{W}\T{\matr{S}}=\hat{\matr{U}}\T{\matr{S}}=\sum\limits_{i=1}^{r}\hat{U}_i \T{S}_i$, где $\hat{U}_i$ --- столбцы матрицы $\hat{\matr{U}}=\matr{U}\matr{\Lambda}^{1/2}\matr{W}$.
\end{proof}
%\begin{remark}
%\label{SSA_AMUSE_decomp_note}
%	$\hat{U}_i=\matr{U}\matr{\Lambda}^{1/2}W_i$, где $W_i$ являются столбцами матрицы $\matr{W}$.
%\end{remark}

\subsection{Алгоритм}
\label{SSA_ICA_alg}
\label{sec:alg}

Как уже говорилось, алгоритм SSA-AMUSE строит разложение некоторой сгруппированной матрицы $\matr{Y}=\matr{X}_I$, которая была
получена на шаге Разложение метода Basic SSA и которая является приближением ранга $r$ траекторной матрицей ряда $\wtilde\tY_N = \calT^{-1} \calH \matr{Y}$. Алгоритм устроен следующим образом.



\medskip
\textbf{Алгоритм SSA-AMUSE}

\textbf{Вход}: Матрица $\matr{Y}$ размера $L \times K$ ранга $r$, сдвиг $\tau \leq K/2$.
\begin{enumerate}
    	\item Построим сингулярное разложение матрицы $\left[\lefttau{\matr{Y}}:\righttau{\matr{Y}}\right]$, которое по лемме \ref{svd_YY_} имеет вид
    		$
    			\left[\lefttau{\matr{Y}}:\righttau{\matr{Y}}\right]=
    				\matr{U}\matr{\Lambda}^{1/2}\left[\T{\bracket{\toptau{\matr{Q}}}}:\T{\bracket{\bottau{\matr{Q}}}}\right], \mbox{ где } \matr{\Q}=\T{\matr{Y}}\matr{U}\matr{\Lambda}^{-1/2}.$
    				
    	    \item Получаем $\matr{W}=\left[W_1:\ldots:W_r \right]$, где $W_i$, $i=1,\ldots,r$, --- собственные векторы матрицы $\matr{C}_{\tau}\brackettt{\matr{\Q}}$.
        \item Вычисляем $\matr{S} = \left[S_1: \ldots :S_r\right]= \matr{\Q}\matr{W}$.
        \item Строим $\hat{\matr{U}}=\left[\hat{U}_1:\ldots:\hat{U}_r\right] = \matr{U}\matr{\Lambda}^{1/2}\matr{W}$.
        \item По теореме \ref{SSA_AMUSE_decomp} $\matr{Y}=\hat{\matr{U}}\T{\matr{S}}$. Поэтому получаем разложение на элементарные матрицы
        \begin{equation}
        	\matr{Y} =\sum\limits_{i=1}^{r}\matr{Y}_i, \mbox{ где } \matr{Y}_i=\hat{U}_i\:\T{S}_{i}.
        	\label{decompY}
        \end{equation}
        \item Проводим группировку: разбиваем $\left\{ 1,\ldots,r \right\}=\bigsqcup\limits_{m=1}^{l} J_m$, считаем результирующие матрицы $\matr{Y}_{J_m}=\sum\limits_{k \in J_m}\matr{Y}_k$, получаем разложение $\matr{Y}=\matr{Y}_{J_1}+\ldots+\matr{Y}_{J_l}$.
        \item Восстанавливаем компоненты ряда:
        $
\wtilde\tY_N = \wtilde\tY^{(1)}_N+\ldots+\wtilde\tY^{(l)}_N,$ где $\wtilde\tY^{(k)}_N = \calT^{-1} \calH \matr{Y}_{J_k}.
$
\end{enumerate}
    \textbf{Результат}: разложение ряда $\wtilde\tY_N$ на сумму компонент $\wtilde\tY_N = \wtilde\tY^{(1)}_N+\ldots+\wtilde\tY^{(l)}_N$.

\section{Разделимость}

\label{SSA_ICA_separ}

Далее будем считать, что матрица $\matr{Y}=\matr{X}_I$ в алгоритме SSA-AMUSE является траекторной матрицей $\matr{X}$ исходного ряда $\tX_N$, соответственно $r=d$, $I=\left\{ 1,\ldots, r \right\}$.
%для удобства изложения будем предполагать в этом разделе, что траекторная матрица $\matr{X}$ ряда $\tX_N$
%имеет ранг $d$. В качестве групп индексов $I$ в алгоритмах будем брать номера
%ненулевых сингулярных чисел сингулярного разложения траекторной матрицы. Соответственно, сгруппированная
%матрица $\matr{Y}=\matr{X}_I=\matr{X}$ и имеет ранг $r=d$.
В общем случае, группа $I$ может соответствовать компоненте ряда,
сильно отделимой от остатка.

%\subsection{Свойства подпространств}
\subsection{Вспомогательные утверждения}
\label{SSA_ICA_prop}
Будем рассматривать ряды $\tX_N$, $\tX_N^{(1)}$ и $\tX_N^{(2)}$ конечного ранга, управляемые ЛРФ порядка $d$, $d_1$ и $d_2$ соответственно, и пространства строк $\gX^{(K,1)},\gX^{(K,2)}$ и $\gX^{(K)}$ их траекторных матриц $\matr{X}$, $\matr{X}^{(1)}$ и $\matr{X}^{(2)}$.
Предположим, что  $\tX_N=\tX_N^{(1)}+\tX_N^{(2)}$ и $d=d_1+d_2$.
Докажем несколько утверждений о свойствах траекторных пространств.

%Как и раньше,  пусть $\gX^{(K,1)},\gX^{(K,2)}$ и $\gX^{(K)}$ --- пространства строк траекторных матриц рядов $\tX_N^{(1)}$, $\tX_N^{(2)}$ и $\tX_N$ %размерности, соответственно, $d_1$, $d_2$ и $d$.
 Обозначим $\righttau{{\gX}^{(K,1)}},\:\righttau{{\gX}^{(K,2)}}$ и $\righttau{{\gX}^{(K)}}$ --- пространства строк матриц $\righttau{\matr{X}}$, $\righttau{\matr{X}^{(1)}}$ и $\righttau{\matr{X}^{(2)}}$, и также $\lefttau{{\gX}^{(K,1)}}$, $\lefttau{{\gX}^{(K,2)}}$ и $\lefttau{{\gX}^{(K)}}$ --- пространства строк матриц $\lefttau{\matr{X}}$, $\lefttau{\matr{X}^{(1)}}$ и $\lefttau{\matr{X}^{(2)}}$.

\begin{lemma}
	\label{UpBottau_spaces}
	Если ряд $\tX_N$ управляется минимальной ЛРФ порядка $d < N/2$, $\tau \leq \min\!\bracket{K - d, \bracket{L - d}/{2}}$, то
	$
		\righttau{{\gX}^{(K)}}\!=\!\lefttau{{\gX}^{(K)}}.
	$
При этом $\func{\dim}\bracket{\righttau{{\gX}^{(K)}}}\!=\!\func{dim}\bracket{\lefttau{{\gX}^{(K)}}}\!=\!\func{dim}\bracket{\gX^{(K)}}=d$.
\end{lemma}
\begin{proof}
	
	Так как в матрице $\righttau{\matr{X}}$ строки с $\tau+1$ по $L$ совпадают со строками с первой по $L-\tau$ матрицы $\lefttau{\matr{X}}$, то для доказательства равенства подпространств остаётся показать, что строки с первой по $\tau$ матрицы $\righttau{\matr{X}}$ принадлежат пространству $\lefttau{{\gX}^{(K)}}$ и строки с $L-\tau+1$ по $L$ принадлежат $\righttau{{\gX}^{(K)}}$. Действительно, это так, так как ряд управляется ЛРФ порядка $d \leq L-2\tau$, и указанные строки являются линейными комбинациями совпадающих строк.


Докажем теперь равенство размерностей неполного и полного пространств.
Очевидно, что $\func{dim}\bracket{\righttau{{\gX}^{(K)}}}=\func{dim}\bracket{\lefttau{{\gX}^{(K)}}}$ и $\func{\dim}\bracket{\righttau{{\gX}^{(K)}}} \leq \func{dim}\bracket{\gX^{(K)}}$.
Рассмотрим базис $V_1,\ldots,V_d$ в $\gX^{(K)}$, составленный из $d$ линейно независимых столбцов матрицы $\matr{X}$.
Соответствующие ему векторы $\bottau{{V_1}},\ldots,\bottau{{V_d}} \in \righttau{{\gX}^{(K)}}$ линейно независимы, так как иначе их можно было бы достроить по ЛРФ порядка $d \leq K-\tau$ до
зависимых векторов, совпадающих по однозначности с $V_1,\ldots,V_d$. Лемма доказана.
\end{proof}



Приведём еще одну лемму, которая будет использована в выводе условий сильной SSA-AMUSE разделимости.

\begin{lemma}
\label{one_tau_deter_cons}
	Пусть $\wtilde{\matr{S}}$ --- некоторая матрица ранга $d$ такая, что для фиксированного $\tau > 0$ выполняется $\matr{C}_{\tau}\brackettt{\wtilde{\matr{S}}}=\func{diag}\bracket{\mu_1,\ldots,\mu_d}$, где $\mu_1 \geq \mu_2 \geq \ldots \geq \mu_d$,
   и $\wtilde{\matr{W}}$ --- некоторая ортогональная матрица. Обозначим $\wtilde{\matr{Q}}=\wtilde{\matr{S}}\T{\wtilde{\matr{W}}}$. Если для некоторых подмножеств $I_1 \subset \left\{ 1,\ldots, d\right\}$ и $I_2 \subset \left\{ 1,\ldots, d\right\}$ множества $\lbrace \mu_i, i \in I_1 \rbrace$ и $\lbrace \mu_j, j \in I_2 \rbrace$ не пересекаются, то для любого спектрального разложения матрицы $\matr{C}_{\tau}\brackettt{\wtilde{\matr{Q}}}=\matr{H}\matr{D}\T{\matr{H}}$ с собственными числами, упорядоченными по убыванию, выполнено
	\begin{enumerate}
		\item $\matr{D}=\matr{C}_{\tau}\brackettt{\wtilde{\matr{S}}}$,
		\item $\func{span}\bracket{H_k: k \in I_1}=\func{span}\bracket{\wtilde{W}_l: l \in I_1}$ и $\func{span}\bracket{H_k: k \in I_2}=\func{span}\bracket{\wtilde{W}_l: l \in I_2}$, где $H_i$, $i=1,\ldots,d$, --- столбцы матрицы $\matr{H}$, $\wtilde{W}_j$, $j=1,\ldots,d$, --- столбцы матрицы $\wtilde{\matr{W}}$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	По лемме \ref{C_S_diag} матрицы $\matr{C}_{\tau}\brackettt{\wtilde{\matr{Q}}}$ и $\matr{C}_{\tau}\brackettt{\wtilde{\matr{S}}}$ подобны, поэтому у них
совпадают собственные числа, что доказывает первый пункт леммы. Также из подобия матриц следует, что столбцы матрицы $\wtilde{\matr{W}}$ являются ортонормированными собственными векторами матрицы $\matr{C}_{\tau}\brackettt{\wtilde{\matr{Q}}}$.	
	Так как подмножества собственных чисел не пересекаются, то подпространства собственных векторов, соответствующие этим подмножествам, определены однозначно. При этом, векторы $\wtilde{W}_i$, $i \in I_1$, и $\wtilde{W}_j$, $j \in I_2$, являются ортогональными базисами этих подпространств, а векторы $H_i$, $i \in I_1$, и $H_j$, $j \in I_2$, образуют другие ортогональные базисы этих же подпространств.
\end{proof}

\subsection{Условия разделимости}
\label{SSA_ICA_sep_cond}

Пусть $\tX_N=\tX_N^{(1)}+\tX_N^{(2)}$, $\matr{Y}^{(1)}$ и $\matr{Y}^{(2)}$ --- траекторные матрицы рядов $\tX_N^{(1)}$ и $\tX_N^{(2)}$. В дальнейшем будем считать, что неравенство $\tau \leq \min\bracket{ K/2, K - d, \bracket{L - d}\!/{2}}$ выполнено.

Несложно увидеть, что если пространства строк $\lefttau{\gX^{(K,1)}}$ и $\lefttau{\gX^{(K,2)}}$  матриц $\lefttau{{\matr{Y}^{(1)}}}$ и $\lefttau{{\matr{Y}^{(2)}}}$ ортогональны, то ряды $\tX_N^{(1)}$ и $\tX_N^{(2)}$ слабо SSA-AMUSE разделимы. Получим необходимые и достаточные условия SSA-AMUSE разделимости.

\begin{theorem}
Ряды $\tX_N^{(1)}$ и $\tX_N^{(2)}$ слабо SSA-AMUSE разделимы тогда и только тогда, когда
	\begin{gather}
\label{eq:wsep1}
	\righttau{{\matr{Y}^{(1)}}}\!\T{\left[\righttau{\matr{Y}}^{(2)}\right]} + \lefttau{\matr{Y}}^{(1)}\!\T{\left[\lefttau{{\matr{Y}}^{(2)}}\right]}=0,
\end{gather}
\begin{gather}
\label{eq:wsep2}
\righttau{{\matr{Y}^{(1)}}}\!\T{\left[\lefttau{\matr{Y}}^{(2)}\right]} + \lefttau{\matr{Y}}^{(1)}\!\T{\left[\righttau{{\matr{Y}}^{(2)}}\right]}=0.
\end{gather}

\end{theorem}



\begin{proof}
	Приведём схему доказательства.
	
	Необходимость. В обозначениях теоремы \ref{SSA_AMUSE_decomp} существует $\matr{W}=\left[ W_1,\ldots, W_d \right]$ такая, что для $\matr{S}=\matr{Q}\matr{W}=\left[ S_1, \ldots, S_d \right]$ матрица $\matr{C}_{\tau}\brackettt{\matr{S}}$ диагональна и базис $\left\lbrace S_1,\ldots, S_d \right\rbrace$ пространства $\gX^{(K)}$ можно разбить на подмножества $\left\lbrace S_1^{(1)},\ldots, S_{d_1}^{(1)} \right\rbrace$ и $\left\lbrace S_1^{(2)},\ldots, S_{d_2}^{(2)} \right\rbrace$ так, что первое составляет базис $\gX^{(K,1)}$, а второе --- базис $\gX^{(K,2)}$. Переупорядочим столбцы $\matr{S}$ так, что $\matr{S}^{(i)}=\left[ S_1^{(i)}:\ldots: S_{d_i}^{(i)} \right],\: i=1,2$, $\matr{S}=\left[ \matr{S}^{(1)}: \matr{S}^{(2)} \right]$. Обозначим $\boldsymbol\Xi^{(i)} = \T{\left[\!\T{\bracket{\toptau{{\matr{S}}^{(i)}}}}\!:\!\T{\bracket{\bottau{{\matr{S}}^{(i)}}}}\!\right]}$. Столбцы матрицы $\boldsymbol\Xi^{(1)}$ ортогональны столбцам $\boldsymbol\Xi^{(2)}$, при этом столбцы матрицы $\boldsymbol\Xi^{(i)}$ образуют ортогональный базис строк матрицы $\left[\!\lefttau{{\matr{Y}}^{(i)}}:\righttau{{\matr{Y}}^{(i)}}\!\right]$. Отсюда следует равенство \eqref{eq:wsep1}.
%	
	Используя определение~\ref{def:sep_w} разделимости,
	 можно показать, что матрица $\matr{P}^{(i)}\!=\!\matr{U}\!\matr{\Lambda}^{1/2}\matr{W}^{(i)}\!\T{\bracket{\!\matr{W}^{(i)}\!}}\!\!\matr{\Lambda}^{-1/2}\T{\matr{U}}$ задает ортогональный проектор на пространство столбцов матрицы $\matr{Y}^{(i)}$.
%и поэтому $\matr{Y}^{(i)}=\matr{P}^{(i)}\matr{Y}=\matr{P}^{(i)}\matr{P}^{(i)}\matr{Y}=\matr{P}^{(i)}\matr{Y}^{(i)}$.
	Воспользовавшись этим, выведем второе условие из диагональности матрицы $\matr{C}_{\tau}\brackettt{\matr{S}}$. Матрица может быть записана в виде
	\begin{eqnarray*}
		\matr{C}_{\tau}\brackettt{\matr{S}} = \left(\begin{array}{cc}
		\matr{C}_{\tau}\brackettt{\matr{S}^{(1)}} & \matr{C}^{(1,2)} \\
		\T{\bracket{\matr{C}^{(1,2)}}} & \matr{C}_{\tau}\brackettt{\matr{S}^{(2)}}
	\end{array}\right),
	\end{eqnarray*}
	где
		$\matr{C}^{(1,2)} = \T{\bracket{\!\matr{W}^{(1)}}\!}\!\matr{\Lambda}^{-1/2}\T{\matr{U}}\left[\righttau{{\matr{Y}}^{(1)}}\T{\bracket{\lefttau{{\matr{Y}}}^{(2)}}}+
\lefttau{{\matr{Y}}^{(1)}}\T{\bracket{\righttau{{\matr{Y}}^{(2)}}}}\right]\matr{U}\!\matr{\Lambda}^{-1/2}\matr{W}^{(2)}/2$ и равно нулю по условию диагональности.
	Домножим выражение для $\matr{C}^{(1,2)}$ справа на $\T{\bracket{\matr{W}^{(i)}}}\matr{\Lambda}^{-1/2}\T{\matr{U}}$ и слева на $\matr{U}\matr{\Lambda}^{1/2}\matr{W}^{(i)}$, воспользуемся свойствами проекторов $\matr{P}^{(i)}$ и получим условие \eqref{eq:wsep2}.
	
	Достаточность. По условию \eqref{eq:wsep1} и лемме \ref{svd_YY_} существуют матрицы  $\matr{S}^{(1)}$ и $\matr{S}^{(2)}$, чьи столбцы образуют базисы $\gX^{(K,1)}$ и $\gX^{(K,2)}$, причём столбцы матрицы $\boldsymbol\Xi^{(1)}$ ортогональны друг другу и столбцам $\boldsymbol\Xi^{(2)}$ (матрицы $\boldsymbol\Xi^{(i)}$ определяются так же,
как при доказательстве необходимости).
Отсюда можно вывести, что столбцы матрицы $\matr{S}=\left[ \matr{S}^{(1)}: \matr{S}^{(2)}\right]$ образуют базис $\gX^{(K)}$.	
	Из условия \eqref{eq:wsep2} следует, что матрица $\matr{C}_{\tau}\brackettt{\matr{S}}$
	 диагональна. Далее рассмотрим выражения $\left[\!\lefttau{{\matr{Y}}^{(i)}}:\righttau{{\matr{Y}}^{(i)}}\!\right]=\left[\!\lefttau{{\matr{Y}}}:\righttau{{\matr{Y}}}\!\right]\boldsymbol\Xi^{(i)}\T{\bracket{\boldsymbol\Xi^{(i)}}}$. Заменим $\left[\!\lefttau{{\matr{Y}}}:\righttau{{\matr{Y}}}\!\right]$ на сингулярное разложение $\matr{U}\matr{\Lambda}^{1/2}\left[\T{\bracket{\toptau{\matr{Q}}}}:\T{\bracket{\bottau{\matr{Q}}}}\right]$, при этом $\matr{Q}=\matr{S}\T{\matr{W}}$ для некоторой ортогональной матрицы $\matr{W}=\left[ \matr{W}^{(1)}:\matr{W}^{(2)} \right]$, $\matr{S}^{(i)}=\matr{Q}\matr{W}^{(i)}$. После подстановки можно вывести $\left[\!\lefttau{{\matr{Y}}^{(i)}}:\righttau{{\matr{Y}}^{(i)}}\!\right]=\matr{U}\matr{\Lambda}^{1/2}\matr{W}^{(i)}\T{\bracket{\boldsymbol\Xi^{(i)}}}$. Но $\matr{Y}^{(i)}\!=\!\matr{A}^{(i)}\!\T{\bracket{\matr{S}^{(i)}}}$ для некоторой матрицы $\matr{A}^{(i)}$ (так как столбцы $\matr{S}^{(i)}$ --- базис строк $\matr{Y}^{(i)}$), и $\left[\!\lefttau{{\matr{Y}}^{(i)}}:\righttau{{\matr{Y}}^{(i)}}\!\right]\!=\!\matr{A}^{(i)}\T{\bracket{\boldsymbol\Xi^{(i)}}}$. Откуда $\matr{A}^{(i)}=\matr{U}\matr{\Lambda}^{1/2}\matr{W}^{(i)}$ и $\matr{Y}^{(i)}=\matr{U}\matr{\Lambda}^{1/2}\matr{W}^{(i)}\T{\bracket{\matr{S}^{(i)}}}$.
%	 Далее остаётся спроектировать траекторные матрицы на найденный базис и найти элементарные матрицы:
%$
%		\matr{Y}^{(i)}=\matr{Y}^{(i)}\matr{S}^{(i)}\bracket{\T{\bracket{\matr{S}^{(i)}}}\matr{S}^{(i)}}^{-1}\T{\bracket{\matr{S}^{(i)}}},
%$
%что и означает разделимость.
\end{proof}

\begin{consequence}
\label{cons:sep}
Если $\righttau{{\gX}^{(K,1)}}$ ортогонально $\righttau{{\gX}^{(K,2)}}$, то ряды слабо SSA-AMUSE разделимы.
\end{consequence}
\begin{remark}
	По лемме \ref{UpBottau_spaces}\  $\righttau{{\gX}^{(K,i)}}=\lefttau{{\gX}^{(K,i)}}$, поэтому вместо $\righttau{{\gX}^{(K,i)}}$ в следствии~\ref{cons:sep} можно использовать $\lefttau{{\gX}^{(K,i)}}$.
\end{remark}

Рассмотрим сингулярные разложения
			\begin{gather}	
\label{eq:QQ}	
				\left[\lefttau{\matr{Y}^{(i)}}:\righttau{\matr{Y}^{(i)}}\right]=
    				\matr{U}^{(i)}\bracket{\matr{\Lambda}^{(i)}}^{1/2}\left[\T{\bracket{\toptau{{\matr{\Q}^{(i)}}}}}:\T{\bracket{\bottau{{\matr{\Q}^{(i)}}}}}\right], i=1,2,
    		\end{gather}
как в лемме \ref{svd_YY_}.

\begin{theorem}
\label{strong_separ}
	Пусть ряды $\tX^{(1)}_N$ и $\tX^{(2)}_N$ слабо SSA-AMUSE разделимы, $\matr{Y}^{(1)}$ и $\matr{Y}^{(2)}$ --- их траекторные матрицы,
а матрицы $\matr{Q}^{(i)}$, $i=1,2$, определены равенством \eqref{eq:QQ}.
Тогда сильная SSA-AMUSE разделимость равносильна тому, что множества
 собственных чисел матриц $\matr{C}_{\tau}\brackettt{\matr{Q}^{(1)}}$ и $\matr{C}_{\tau}\brackettt{\matr{Q}^{(2)}}$
не пересекаются.
%	\end{itemize}
\end{theorem}
\begin{proof}
Доказательство теоремы основывается на лемме \ref{one_tau_deter_cons}, в силу которой компоненты разложения,
соответствующие разделяемым компонентам ряда, не могут перемешаться.
\end{proof}

 Заметим, что условия сильной разделимости не зависят от выбора базисов $\matr{Q}^{(i)}$, $i=1,2$, удовлетворяющих условиям теоремы.

Следующее утверждение показывает, как связаны условия слабой разделимости при применении Basic SSA и SSA-AMUSE. Доказательство его непосредственно
следует из формулировки условий разделимости.

\begin{proposition}
\label{prop:sepSSAandAMUSE}
Пусть $\tX^{(1)}_{N+\tau}$ и $\tX^{(2)}_{N+\tau}$ --- ряды длины $N+\tau$, управляемые ЛРФ порядка $d < N/2$, при этом ряды $\tX^{(i)}_{N}$ из первых $N$ элементов $\tX^{(i)}_{N+\tau}$ слабо Basic SSA разделимы при длине окна $L$. Пусть также $\tau$, $L$, $K=N-L+1$ и $d$ такие, что $\tau \leq \min \bracket{K/2, K\!-\!d, \bracket{L-d}\!/{2}}$. Тогда
\begin{enumerate}
	\item $\tX^{(1)}_{N+\tau}$ и $\tX^{(2)}_{N+\tau}$ слабо SSA-AMUSE разделимы при том же $L$ и сдвиге $\tau$.
	\item Если $\tau \leq \bracket{L-d}/3$, то $\tX^{(1)}_{N}$ и $\tX^{(2)}_{N}$ слабо SSA-AMUSE разделимы при длине окна $L-\tau$ и сдвиге $\tau$.
\end{enumerate}
\end{proposition}

\begin{remark}
\label{rem:sepSSAandAMUSE}
Заметим, что для SSA-AMUSE разделимости достаточно только ортогональности отрезков ряда длины $K-\tau$
и не нужна ортогональность отрезков ряда длины $L$, в то время как для Basic SSA условия разделимости зависят как
от $K$, так и от $L$.
\end{remark}

\subsection{Примеры слабой и сильной разделимости}
\label{SSA_ICA_exampl}

Приведём примеры, в которых проявляются особенности и плюсы SSA-AMUSE разделимости.
Ниже будем рассматривать только случай $\tau=1$, так как при нём проявляются все преимущества
метода SSA-AMUSE.

\begin{enumerate}
	\item Приведём пример того, что условие  $\lefttau{\gX^{(K,1)}} \perp \; \lefttau{\gX^{(K,2)}}$  является лишь достаточным условием слабой разделимости.
	\label{sinsin_str_ex}
	Рассмотрим $\tX^{(1)}=(\cos \pi n, n=1,\ldots,N)$ и $\tX^{(2)}=(\func{const}, n=1,\ldots,N)$. Если $K$ чётно, то при $\tau=1$ пространства $\lefttau{\gX^{(K,1)}}$ и $\lefttau{\gX^{(K,2)}}$ не ортогональны, однако условия \eqref{eq:wsep1} и \eqref{eq:wsep2} выполнены. Таким образом, данные ряды слабо SSA-AMUSE разделимы.
	
	\item Получим условия сильной разделимости двух гармоник.
	Рассмотрим ряды $\tX^{(1)}$ и $\tX^{(2)}$ длины $N$ с общими членами в виде $x^{(i)}_n=A_i\sin \bracket{2\pi n \omega_i + \gamma_i}$, $n=1,\ldots,N$, $0<\omega_i \leq 0.5$, $\omega_1\neq\omega_2$. Докажем, что если $(K-1)\omega_1$ и $(K-1)\omega_2$ целые, то ряды сильно SSA-AMUSE разделимы. Слабая разделимость следует из $\lefttau{\gX^{(K,1)}} \perp \lefttau{\gX^{(K,2)}}$. Сильную разделимость можно доказать  следующим образом. Пусть для определённости $\omega_i<0.5$. В этом случае найденный на шаге 3 алгоритма SSA-AMUSE базис из столбцов матрицы $\matr{S}$ можно разбить на базисы пространств $\gX^{(K,1)}$ и $\gX^{(K,2)}$ вида:
	\begin{gather*}
		S_1^{(i)}=\T{\bracket{A\sin\bracket{2\pi \omega_i +\zeta_i},\ldots,A\sin\bracket{2\pi \omega_i K +\zeta_i}}},\\
		S_2^{(i)}=\T{\bracket{A\cos\bracket{2\pi \omega_i +\zeta_i},\ldots,A\cos\bracket{2\pi \omega_i K +\zeta_i}}},
	\end{gather*}
	где $A=1/\sqrt{K-1}$.
	
	К тому же, для таких базисов каждая из матриц $\matr{C}_{\tau}\brackettt{\matr{S}^{(i)}}$, $i=1,2$, диагональна, при этом на диагоналях стоят числа ${\cos\bracket{2\pi \omega_i}}/{2}$, они же являются собственными числами этих матриц. Поэтому условия сильной разделимости в теореме~\ref{strong_separ}
 выполнены.

Заметим, что в случае применения алгоритма SSA-AMUSE полученные на шаге 3 столбцы матрицы $\matr{S}$ будут упорядочены по значениям $\cos\bracket{2\pi \omega_i}$, в то время как в Basic SSA они упорядочены по амплитудам $A_i$. Упорядоченность по $A_i$ приводит к смешиванию в случае совпадающих амплитуд.

\end{enumerate}

\subsection{SSA-AMUSE асимптотическая разделимость}
\label{SSA_ICA_asymp}

Конечно, в реальных задачах условия точной разделимости редко выполнены и имеет место приближённая разделимость,
которая является следствием наличия асимптотической разделимости.

Пусть $\tX^{(i)}=\brackettt{x_1^{(i)},x_2^{(i)},\ldots}$, $i=1,2$, --- бесконечные ряды, управляемые ЛРФ. Обозначим $\tX^{(i)}_N=\brackettt{x_1^{(i)},x_2^{(i)},\ldots,x_N^{(i)}}.$

Понятие асимптотической SSA-AMUSE слабой разделимости рядов $\tX^{(1)}$ и $\tX^{(2)}$ определяется аналогично асимптотической разделимости
в случае Basic SSA с помощью замены условия точной  ортогональности на асимптотическую при длине ряда $N$, стремящейся к бесконечности.
При этом в случае SSA-AMUSE не требуется, чтобы $L$ также стремилось к бесконечности,
и достаточно, чтобы только $K=N-L+1\rightarrow \infty$ при $N\rightarrow \infty$
(смотри замечание \ref{rem:sepSSAandAMUSE}).

Таким образом, те ряды, которые были слабо асимптотически разделимыми с помощью Basic SSA,
остаются слабо асимптотически разделимыми с помощью SSA-AMUSE, при этом $L$ может не стремиться
к бесконечности.


Отдельно остановимся на понятии асимптотической сильной разделимости.
Условием сильной разделимости в SSA-AMUSE является дизъюнктность множеств собственных чисел матриц $\matr{C}_{\tau}\brackettt{\matr{S}^{(K,i)}}$, где $\matr{S}^{(K,i)}$ --- матрицы, чьи столбцы содержат базисы, найденные на шаге 3 алгоритма SSA-AMUSE, применённого к траекторным матрицам рядов $\tX^{(i)}_N$.
Условием асимптотической сильной разделимости асимптотически слабо разделимых рядов назовём дизъюнктность множеств предельных собственных
чисел матриц $\matr{C}_{\tau}\brackettt{\matr{S}^{(K,i)}}$ при $K\rightarrow\infty$, если такие пределы существуют.

Метод SSA-AMUSE ослабляет условия метода Basic SSA и для асимптотической сильной разделимости.
А именно, гармоники $\tX^{(1)}$ и $\tX^{(2)}$  с общими членами в виде $x^{(i)}_n\!=\!A_i\sin\! \bracket{2\pi n \omega_i + \gamma_i}$, $n=1,2,\ldots$, являются асимптотически сильно разделимыми даже при совпадающих
амплитудах при $K\rightarrow \infty$. Это доказывается непосредственным вычислением собственных чисел матриц $\matr{C}_{\tau}\brackettt{\matr{S}^{(K,i)}}$.%


\section{Сравнение}
\label{Comparison}

Так как оба метода, предлагаемый в статье SSA-AMUSE и введённый в \cite{DerivSSA} DerivSSA, используются для ослабления условий сильной разделимости, возникает задача их сравнения.
У методов много общего. В частности, они оба являются вложенными, т.е. используются уже после выделения сигнала из шума.

\bfgh
%\label{fig:comp}
	\centering
	%width = 0.3\textwidth, height=0.5\textheight
	\includegraphics[scale=0.785]{figure1.eps}
%	\captionsetup{labelformat=empty}
	\caption{RMSE для оценки $\tX^{(1)}_N$ в зависимости от  $\omega_2$.}
\label{fig:comp}
\efg


Из преимуществ SSA-AMUSE перед DerivSSA можно отметить возможность точной разделимости компонент, которая
отсутствует в DerivSSA. Также, для случая приближенного или асимптотического разделения гармоник в DerivSSA накладываются некоторые дополнительные
условия на амплитуды, в то время как в случае SSA-AMUSE такие условия отсутствуют. Некоторым недостатком SSA-AMUSE
является то, что получаемое разложение не является разложением на ортогональные по Фробениусу матрицы.

Тем не менее, перечисленные преимущества приводят к повышению точности разделения компонент временного ряда.
Продемонстрируем это на численном эксперименте. Пусть $\tX_N=\tX^{(1)}_N+\tX^{(2)}_N$, где общий член $x^{(i)}_n\!=\sin\! \bracket{2\pi n \omega_i}$, $n=1,\ldots,N$. Параметр $\omega_1=1/7$, $\omega_2$ меняется от 0.01 до 0.25 с шагом 0.001, длина ряда $N=150$, длина окна $L=75$, сдвиг $\tau=1$ и в DerivSSA параметр $\gamma=10$. На рисунке \ref{fig:comp} изображены ошибки RMSE оценки одной гармонической компоненты по наблюдаемой сумме двух синусов. Естественно, что при $\omega_2\approx \omega_1=1/7$ разделимости нет. Однако видно, что область с большой ошибкой вокруг $\omega_2=1/7\approx 0.14$  более узкая для SSA-AMUSE.
При добавлении шума к сигналу результат сравнения аналогичен.

%\bibliographystyle{gost2008}

%\bibliography{assa3}

\begin{thebibliography}{1}
\def\selectlanguageifdefined#1{
\expandafter\ifx\csname date#1\endcsname\relax
\else\selectlanguage{#1}\fi}
\providecommand*{\href}[2]{{\small #2}}
\providecommand*{\url}[1]{{\small #1}}
\providecommand*{\BibUrl}[1]{\url{#1}}
\providecommand{\BibAnnote}[1]{}
\providecommand*{\BibEmph}[1]{#1}
\ProvideTextCommandDefault{\cyrdash}{\hbox to.8em{--\hss--}}
\providecommand*{\BibDash}{\ifdim\lastskip>0pt\unskip\nobreak\hskip.2em\fi
\cyrdash\hskip.2em\ignorespaces}

\bibitem{Golyandina.etal2001}
\selectlanguageifdefined{english}
\BibEmph{Golyandina~N., Nekrutkin~V., Zhigljavsky~A.} Analysis of Time Series
  Structure: {SSA} and Related Techniques. \BibDash
\newblock Chapman\&Hall/CRC, 2001.

\bibitem{Golyandina.Zhigljavsky2012}
\selectlanguageifdefined{english}
\BibEmph{Golyandina~N., Zhigljavsky~A.} {S}ingular {S}pectrum {A}nalysis for
  Time Series. Springer Briefs in Statistics. \BibDash
\newblock Springer, 2013.

\bibitem{Golyandina.etal2003}
\selectlanguageifdefined{russian}
\BibEmph{Голяндина~Н., Некруткин~В., Степанов~Д.}. Варианты метода ``Гусеница''-SSA для анализа многомерных
  временных рядов~// Труды II Международной конференции ``Идентификация систем и задачи управления'' SICPRO'03. Москва. \BibDash
\newblock 2003. \BibDash
\newblock P.~2139--2168.

\bibitem{DerivSSA}
\selectlanguageifdefined{english}
\BibEmph{Golyandina~N., Shlemov~A.} Variations of singular spectrum analysis
  for separability improvement: non-orthogonal decompositions of time
  series.~// \BibEmph{Statistics and Its Interface}. \BibDash
\newblock 2015. \BibDash
\newblock Vol.~8, no.~3. \BibDash
\newblock P.~277--294.

\bibitem{HyvarinenE2000}
\selectlanguageifdefined{english}
\BibEmph{Hyvarinen~A., Karhunen~J., Erkki~O.} Independent Component Analysis.
  \BibDash
\newblock John Wiley \& Sons,Inc., 2001. \BibDash
\newblock 320~p.

\bibitem{Hyvarinen99}
\selectlanguageifdefined{english}
\BibEmph{Hyvarinen~A.} Fast and robust fixed-point algorithms for independent
  component analysis.~// \BibEmph{Neural Networks, IEEE Transactions}. \BibDash
\newblock 1999. \BibDash
\newblock Vol.~10, no.~3. \BibDash
\newblock P.~626--634.

\bibitem{Tong1991}
\selectlanguageifdefined{english}
\BibEmph{Tong~L., Liu~R. et~al.} Indeterminacy and identifiability of blind
  identification.~// \BibEmph{IEEE Transactions on Circuits and Systems}.
  \BibDash
\newblock 1991. \BibDash
\newblock Vol.~38, no.~5. \BibDash
\newblock P.~499--509.

\bibitem{Cardoso}
\selectlanguageifdefined{english}
\BibEmph{Belouchrani~A., {Abed-Meraim}~K. et~al.} A blind source separation
  technique using second order statistics.~// \BibEmph{IEEE Transactions on
  Signal Processing}. \BibDash
\newblock 1997. \BibDash
\newblock Vol.~45, no.~2. \BibDash
\newblock P.~434--444.

\bibitem{Usevich2010}
\selectlanguageifdefined{english}
\BibEmph{Usevich~K.} On signal and extraneous roots in {Singular Spectrum
  Analysis}~// \BibEmph{Stat. Interface}. \BibDash
\newblock 2010. \BibDash
\newblock Vol.~3, no.~3. \BibDash
\newblock P.~281--295.


\end{thebibliography}
\end{document}


